{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxUrEenNYdI3",
    "outputId": "44b191d3-8e12-437f-c7b7-95f17ed56f1c"
   },
   "source": [
    "!wget https://cluster.ig.umons.ac.be/workshop_ia/image.orig.zip"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brMbmmT1aspS"
   },
   "source": [
    "!unzip image.orig.zip"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J3A3Aw_oYtLu"
   },
   "source": [
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications import vgg16\n",
    "from keras.applications import vgg19\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import mobilenet\n",
    "from keras.applications import xception\n",
    "from matplotlib.pyplot import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import math\n",
    "from keras.models import Model\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4M9n0rfqY86Y"
   },
   "source": [
    "def euclidianDistance(l1,l2):\n",
    "    distance = 0\n",
    "    length = min(len(l1),len(l2))\n",
    "    for i in range(length):\n",
    "        distance += pow((l1[i] - l2[i]), 2)\n",
    "    return math.sqrt(distance)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pYGP857DaFQK"
   },
   "source": [
    "def getkVoisins(lfeatures, test, k) :\n",
    "    ldistances = []\n",
    "    for i in range(len(lfeatures)):\n",
    "        dist = euclidianDistance(test[1], lfeatures[i][1])\n",
    "        ldistances.append((lfeatures[i][0], lfeatures[i][1], dist))\n",
    "    ldistances.sort(key=operator.itemgetter(2))\n",
    "    lvoisins = []\n",
    "    for i in range(k):\n",
    "        lvoisins.append(ldistances[i])\n",
    "    return lvoisins"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1MpHbsoaSLm",
    "outputId": "cc23bddf-a396-44e2-a14b-67ef106ea767"
   },
   "source": [
    "model0=vgg16.VGG16(weights='imagenet', include_top=True,pooling='avg')\n",
    "#model1 = Model(inputs=model0.input, outputs=model0.layers[-2].output)\n",
    "#model1 = resnet50.ResNet50(weights='imagenet', include_top=True,pooling='avg')\n",
    "model0 = mobilenet.MobileNet(weights='imagenet', include_top=True,pooling='avg')\n",
    "model1 = Model(inputs=model0.input, outputs=model0.layers[-2].output)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "oxUmzQEnacC4"
   },
   "source": [
    "model1.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rTg-LAHVadhx"
   },
   "source": [
    "files = \"image.orig\"         #Chemin vers la base d'images\n",
    "features1 = []               #Stocker les caractérstiques\n",
    "big_folder=\"Features_train/\" #Dossier pour stocker les caractéristiques\n",
    "if not os.path.exists(big_folder):\n",
    "    os.makedirs(big_folder)\n",
    "folder_model1=\"Features_train/VGG16/\"\n",
    "if not os.path.exists(folder_model1):\n",
    "    os.makedirs(folder_model1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "files = \"image.orig\"         #Chemin vers la base d'images\n",
    "features1 = []               #Stocker les caractérstiques\n",
    "big_folder=\"Features_train/\" #Dossier pour stocker les caractéristiques\n",
    "if not os.path.exists(big_folder):\n",
    "    os.makedirs(big_folder)\n",
    "folder_model1=\"Features_train/MobileNet/\"\n",
    "if not os.path.exists(folder_model1):\n",
    "    os.makedirs(folder_model1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fw4_uANE_ugP"
   },
   "source": [
    "def indexation(output_file):\n",
    "  pas =0\n",
    "  for j in os.listdir(files) :\n",
    "      data = os.path.join(files, j)\n",
    "      print (data)\n",
    "      if not data.endswith(\".jpg\"):\n",
    "          continue\n",
    "      file_name = os.path.basename(data)\n",
    "      # load an image from file\n",
    "      image = load_img(data, target_size=(224, 224))\n",
    "      # convert the image pixels to a numpy array\n",
    "      image = img_to_array(image)\n",
    "      # reshape data for the model\n",
    "      image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "      # prepare the image for the VGG model\n",
    "      image = preprocess_input(image)\n",
    "      # predict the probability across all output classes\n",
    "      feature = model1.predict(image)\n",
    "      feature = np.array(feature[0])\n",
    "      np.savetxt(folder_model1+\"/\"+os.path.splitext(file_name)[0]+\".txt\",feature)\n",
    "      features1.append((data,feature))\n",
    "      print (pas)\n",
    "      pas = pas+1\n",
    "  with open(output_file, \"w\") as output:\n",
    "        output.write(str(features1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "import json \n",
    "import os\n",
    "def indexation(output_file):\n",
    "    pas = 0\n",
    "    for j in os.listdir(files):\n",
    "        data = os.path.join(files, j)\n",
    "        print(data)\n",
    "        if not data.endswith(\".jpg\"):\n",
    "            continue\n",
    "        file_name = os.path.basename(data)\n",
    "        # load an image from file\n",
    "        image = load_img(data, target_size=(224, 224))\n",
    "        # convert the image pixels to a numpy array\n",
    "        image = img_to_array(image)\n",
    "        # reshape data for the model\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        # prepare the image for the VGG model\n",
    "        image = preprocess_input(image)\n",
    "        # predict the probability across all output classes\n",
    "        feature = model1.predict(image)\n",
    "        feature = np.array(feature[0])\n",
    "        np.savetxt(os.path.join(folder_model1, os.path.splitext(file_name)[0] + \".txt\"), feature)\n",
    "        features1.append((data, feature.tolist()))  # Convert feature to list for JSON serialization\n",
    "        print(pas)\n",
    "        pas = pas + 1\n",
    "    with open(output_file, \"w\") as output:\n",
    "        json.dump(features1, output)  # Serialize the list as JSON\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "features1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Read the content of the text file\n",
    "with open(\"Features_train/VGG16.txt\", \"r\") as file:\n",
    "    content = file.read()\n",
    "    content.replace(\"\\n\", \"\")\n",
    "    content = re.sub(r'\\s+', '', content)\n",
    "    # the string is a list, we convert it to a list, we can not use ast.literal_eval because the list contains numpy arrays\n",
    "    content_list = content.strip(\"[]\").split(\"),\")\n",
    "    print(content_list)\n",
    "\n",
    "    for con in content_list:\n",
    "        con.strip(\"(\")\n",
    "        ouicon = con.split(\"',\")       \n",
    "               \n",
    "        name = ouicon[0].strip(\"('\")\n",
    "        #print(name)\n",
    "        array_str = ouicon[1]\n",
    "        array_str = array_str[len(\"array([\"): -len(\",dtype=float32)\") - 1]\n",
    "\n",
    "        # Step 2: Replace \"...\" with a large number of zeros (since '...' indicates repeated zeros)\n",
    "        # Assuming the array has a significant number of zeros in place of \"...\"\n",
    "        # For the purpose of this example, let's assume \"...\" represents 100 zeros\n",
    "        # Adjust this according to the actual meaning of \"...\" in your specific case\n",
    "        array_str = array_str.replace(\"...\", \"Ellipsis\")\n",
    "\n",
    "        # Step 3: Convert the cleaned string into a list of floats\n",
    "        array_list = [float(x) for x in array_str.split(',')]\n",
    "\n",
    "        # Step 4: Convert the list into a numpy array of dtype float32\n",
    "        np_array = np.array(array_list, dtype=np.float32)\n",
    "\n",
    "        print(np_array)\n",
    "        \n",
    "print(content)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def load_features_from_json(input_file):\n",
    "    \"\"\"\n",
    "    Load features from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): Path to the input JSON file.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: A list where each element is a tuple containing the file path and the features as a numpy array.\n",
    "    \"\"\"\n",
    "    features2 = []\n",
    "    with open(input_file, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        for image in data:\n",
    "            name = image[0]\n",
    "            tab = image[1]\n",
    "            # Convert tab to numpy array\n",
    "            tab = np.array(tab)\n",
    "            print(name)\n",
    "            features2.append((name, tab))\n",
    "    \n",
    "    # Convert the features list back to numpy arrays\n",
    "    #features = [(item['file_path'], np.array(item['features'])) for item in data]\n",
    "    return features2\n",
    "\n",
    "features2 = load_features_from_json(\"Features_train/VGG16.json\")\n",
    "\n",
    "\n",
    "# Usage example\n",
    "# features = load_features_from_json(\"output.json\")\n",
    "# for file_path, feature in features:\n",
    "#     print(f\"File: {file_path}, Feature shape: {feature.shape}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "source": [
    "# Original tuple\n",
    "original_tuple = ('image.orig/610.jpg', '[0., 0., 0., ..., 0., 0., 0.] dtype=float32')\n",
    "\n",
    "# Convert the string representation of the array to an actual array\n",
    "import numpy as np\n",
    "array = np.fromstring(original_tuple[1][1:-1], sep=', ')\n",
    "\n",
    "# Create the new tuple with the array\n",
    "new_tuple = (original_tuple[0], array)\n",
    "\n",
    "# Print the new tuple\n",
    "print(new_tuple)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pO7ZEY_x_6RF",
    "outputId": "6074b84f-881a-48cf-89a2-8f0a7ddde073"
   },
   "source": [
    "indexation(\"Features_train/MobileNet.json\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3eDf-p5MhX7x"
   },
   "source": [
    "def recherche(image_req,top, features):\n",
    "  top=20\n",
    "  voisins = getkVoisins(features, features[image_req],top)\n",
    "  #print(voisins)\n",
    "  nom_images_proches = []\n",
    "  nom_images_non_proches = []\n",
    "  for k in range(top):\n",
    "      nom_images_proches.append(voisins[k][0])\n",
    "      #print(\"done\")\n",
    "  plt.figure(figsize=(5, 5))\n",
    "  plt.imshow(imread(features[image_req][0]), cmap='gray', interpolation='none')\n",
    "  plt.title(\"Image requête\")\n",
    "  nom_image_requete=os.path.splitext(os.path.basename(features[image_req][0]))[0]\n",
    "  print(nom_image_requete)\n",
    "  plt.figure(figsize=(25, 25))\n",
    "  plt.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "  for j in range(top):\n",
    "      plt.subplot(int(top/4),int(top/5),j+1)\n",
    "      plt.imshow(imread(nom_images_proches[j]), cmap='gray', interpolation='none')\n",
    "      nom_images_non_proches.append(os.path.splitext(os.path.basename(nom_images_proches[j]))[0])\n",
    "      title = \"Image proche n°\"+str(j)\n",
    "      plt.title(title)\n",
    "  return nom_image_requete, nom_images_proches, nom_images_non_proches"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ssih6cgYdr4J",
    "outputId": "8252533d-a478-49e6-c18d-7e4170602653"
   },
   "source": [
    "nom_image_requete, nom_images_proches, nom_images_non_proches = recherche(5,20,features2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mn9KXJRmCJ9c"
   },
   "source": [
    "RP_file=\"\"\n",
    "def compute_RP(RP_file, top,nom_image_requete, nom_images_non_proches):\n",
    "  text_file = open(RP_file, \"w\")\n",
    "  rappel_precision=[]\n",
    "  rp = []\n",
    "  position1=int(nom_image_requete)//100\n",
    "  for j in range(top):\n",
    "    position2=int(nom_images_non_proches[j])//100\n",
    "    if position1==position2:\n",
    "      rappel_precision.append(\"pertinant\")\n",
    "    else:\n",
    "      rappel_precision.append(\"non pertinant\")\n",
    "\n",
    "  for i in range(top):\n",
    "    j=i\n",
    "    val=0\n",
    "    while j>=0:\n",
    "      if rappel_precision[j]==\"pertinant\":\n",
    "        val+=1\n",
    "      j-=1\n",
    "    rp.append(str((val/(i+1))*100)+\" \"+str((val/top)*100))\n",
    "\n",
    "  with open(RP_file, 'w') as s:\n",
    "    for a in rp:\n",
    "      s.write(str(a) + '\\n')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rMuAiN8FV1l"
   },
   "source": [
    "compute_RP(\"VGG_RP.txt\", 20,nom_image_requete, nom_images_non_proches)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JBMJUE5HSfX"
   },
   "source": [
    "def display_RP(fichier):\n",
    "  x = []\n",
    "  y = []\n",
    "  with open(fichier) as csvfile:\n",
    "      plots = csv.reader(csvfile, delimiter=' ')\n",
    "      for row in plots:\n",
    "          print(f'x,y = {row[0]} {row[1]}')\n",
    "          x.append(float(row[0]))\n",
    "          y.append(float(row[1]))\n",
    "          fig = plt.figure()\n",
    "  plt.plot(y,x,'C1', label=\"VGG16\" );\n",
    "  plt.xlabel('Rappel')\n",
    "  plt.ylabel('Précison')\n",
    "  plt.title(\"R/P\")\n",
    "  plt.legend()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "qUcTKMG-HpmM",
    "outputId": "4fd7cf87-5903-48b8-e123-c315ea972cf8"
   },
   "source": [
    "display_RP(\"VGG_RP.txt\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
